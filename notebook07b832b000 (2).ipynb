{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom string import Template # For generating prompt template\n\nimport os\nimport gc # grabage collector\n# we need to install the sentence transformer and use its embedding to read the faiss index\n#cp stands for a copy. This command is used to copy files or groups of files or directories. \n# The -r option tells rm to remove directories recursively, and the -f option tells it to force the removal of files and directories that are read-only or do not exist\n\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n\n#installing faiss package for reading faiss wikipedia index\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n# as per wikipedia faiss index https://www.kaggle.com/datasets/jjinho/wikipedia-2023-07-faiss-index\nimport faiss\nfrom faiss import write_index, read_index\n\n\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")\n\n# installing langchain package# We will use langchain recursive splitter\n!pip install langchain --no-index --find-links=file:///kaggle/input/llm-pkg/\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:29:27.120771Z","iopub.execute_input":"2023-09-13T02:29:27.121076Z","iopub.status.idle":"2023-09-13T02:31:14.161823Z","shell.execute_reply.started":"2023-09-13T02:29:27.121049Z","shell.execute_reply":"2023-09-13T02:31:14.160788Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Processing ./sentence-transformers\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.32.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.23.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers==2.2.2) (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.6.3)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.3.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers==2.2.2) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers==2.2.2) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126125 sha256=d019f9eeec996d92a1e76a55a904cf946dd46a8d8d4960fa9dd7144158b9f775\n  Stored in directory: /root/.cache/pip/wheels/6c/ea/76/d9a930b223b1d3d5d6aff69458725316b0fe205b854faf1812\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\nProcessing /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\nLooking in links: file:///kaggle/input/llm-pkg/\nProcessing /kaggle/input/llm-pkg/langchain-0.0.247-py3-none-any.whl\nRequirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.17)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.4)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.5.14)\nProcessing /kaggle/input/llm-pkg/langsmith-0.0.15-py3-none-any.whl (from langchain)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.5)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\nProcessing /kaggle/input/llm-pkg/openapi_schema_pydantic-1.2.4-py3-none-any.whl (from langchain)\nRequirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.9)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.6.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\nInstalling collected packages: openapi-schema-pydantic, langsmith, langchain\nSuccessfully installed langchain-0.0.247 langsmith-0.0.15 openapi-schema-pydantic-1.2.4\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading the csv file\n#df_train = pd.read_csv(\"./train.csv\")\ndf_final = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\ndf_final.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:31:36.025272Z","iopub.execute_input":"2023-09-13T02:31:36.025972Z","iopub.status.idle":"2023-09-13T02:31:36.074825Z","shell.execute_reply.started":"2023-09-13T02:31:36.025938Z","shell.execute_reply":"2023-09-13T02:31:36.073851Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E  \n0  MOND is a theory that eliminates the observed ...  \n1  Dynamic scaling refers to the evolution of sel...  \n2  The triskeles symbol is a representation of th...  \n3  Regularizing the mass-energy of an electron wi...  \n4  The angular spacing of features in the diffrac...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"READING WIKIPEDIA FILES TO FIND CONTEXT****","metadata":{}},{"cell_type":"code","source":"# PART 1 - Searching Wikipedia Titles","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:31:39.143383Z","iopub.execute_input":"2023-09-13T02:31:39.143743Z","iopub.status.idle":"2023-09-13T02:31:39.148266Z","shell.execute_reply.started":"2023-09-13T02:31:39.143714Z","shell.execute_reply":"2023-09-13T02:31:39.147125Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# loadding the wikipedia faiss index. This will be used for searching\nsentence_index = read_index(\"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\")","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:31:55.033560Z","iopub.execute_input":"2023-09-13T02:31:55.033969Z","iopub.status.idle":"2023-09-13T02:33:22.833721Z","shell.execute_reply.started":"2023-09-13T02:31:55.033940Z","shell.execute_reply":"2023-09-13T02:33:22.832513Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Creating index of prompts i.e q to serach for relavnt wikipedia documents\nfrom sentence_transformers import SentenceTransformer\nSIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 32\n\nmodel = SentenceTransformer(SIM_MODEL, device='cuda')\nmodel.max_seq_length = MAX_LENGTH\nmodel = model.half() # The model.half() method in PyTorch is used to convert a model to half-precision. This can be useful for reducing the memory footprint of a model, as half-precision numbers use half the memory as single-precision numbers","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:33:22.837155Z","iopub.execute_input":"2023-09-13T02:33:22.837526Z","iopub.status.idle":"2023-09-13T02:33:26.243868Z","shell.execute_reply.started":"2023-09-13T02:33:22.837491Z","shell.execute_reply":"2023-09-13T02:33:26.242859Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"prompt_embeddings = model.encode(df_final['prompt'].values, batch_size=BATCH_SIZE, device=DEVICE, show_progress_bar=True, convert_to_tensor=True, normalize_embeddings=True)\nprompt_embeddings = prompt_embeddings.detach().cpu().numpy() # detach to remove gradients.\nsearch_score, search_index = sentence_index.search(prompt_embeddings, 3)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:33:26.245525Z","iopub.execute_input":"2023-09-13T02:33:26.245945Z","iopub.status.idle":"2023-09-13T02:33:49.587378Z","shell.execute_reply.started":"2023-09-13T02:33:26.245908Z","shell.execute_reply":"2023-09-13T02:33:49.586321Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b753929d6c40149262758ec776eb39"}},"metadata":{}}]},{"cell_type":"code","source":"\ndel sentence_index # deleting as not required. otherwise it will give memory issue\ndel prompt_embeddings\n_ = gc.collect() # garbage collector..frees up memmory","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:33:49.589707Z","iopub.execute_input":"2023-09-13T02:33:49.590118Z","iopub.status.idle":"2023-09-13T02:33:50.472484Z","shell.execute_reply.started":"2023-09-13T02:33:49.590085Z","shell.execute_reply":"2023-09-13T02:33:50.471468Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# PART 2 - Fetching relavant text of wikipedia documents","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:40.829907Z","iopub.execute_input":"2023-09-13T02:36:40.830291Z","iopub.status.idle":"2023-09-13T02:36:40.835309Z","shell.execute_reply.started":"2023-09-13T02:36:40.830262Z","shell.execute_reply":"2023-09-13T02:36:40.834049Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# getting wikipedia documents \ndf_wiki = pd.read_parquet(\"/kaggle/input/wikipedia-20230701/wiki_2023_index.parquet\",\n                     columns=['id', 'file'])","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:41.752767Z","iopub.execute_input":"2023-09-13T02:36:41.754133Z","iopub.status.idle":"2023-09-13T02:36:46.179018Z","shell.execute_reply.started":"2023-09-13T02:36:41.754094Z","shell.execute_reply":"2023-09-13T02:36:46.177939Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"wikipedia_file_data = []\n\nfor i, (scr, idx) in tqdm(enumerate(zip(search_score, search_index)), total=len(search_score)):\n    scr_idx = idx\n    _df = df_wiki.loc[scr_idx].copy()\n    _df['prompt_id'] = i\n    wikipedia_file_data.append(_df)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:46.181854Z","iopub.execute_input":"2023-09-13T02:36:46.182459Z","iopub.status.idle":"2023-09-13T02:36:46.377766Z","shell.execute_reply.started":"2023-09-13T02:36:46.182423Z","shell.execute_reply":"2023-09-13T02:36:46.376735Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08d87af60c5c4fdbae3d8fe39e5f1ce7"}},"metadata":{}}]},{"cell_type":"code","source":"wikipedia_file_data = pd.concat(wikipedia_file_data).reset_index(drop=True)\nwikipedia_file_data = wikipedia_file_data[['id', 'prompt_id', 'file']].drop_duplicates().sort_values(['file', 'id']).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:46.380100Z","iopub.execute_input":"2023-09-13T02:36:46.380873Z","iopub.status.idle":"2023-09-13T02:36:46.417236Z","shell.execute_reply.started":"2023-09-13T02:36:46.380835Z","shell.execute_reply":"2023-09-13T02:36:46.416181Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"wikipedia_file_data.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:46.793425Z","iopub.execute_input":"2023-09-13T02:36:46.794185Z","iopub.status.idle":"2023-09-13T02:36:46.804945Z","shell.execute_reply.started":"2023-09-13T02:36:46.794147Z","shell.execute_reply":"2023-09-13T02:36:46.803702Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id       file\n0      1141        151  a.parquet\n1  11963992        185  a.parquet\n2      1200         63  a.parquet\n3      1234        130  a.parquet\n4      1317         89  a.parquet","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1141</td>\n      <td>151</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11963992</td>\n      <td>185</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200</td>\n      <td>63</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1234</td>\n      <td>130</td>\n      <td>a.parquet</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1317</td>\n      <td>89</td>\n      <td>a.parquet</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"del df_wiki\n_ = gc.collect()\nlibc.malloc_trim(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:49.657674Z","iopub.execute_input":"2023-09-13T02:36:49.659071Z","iopub.status.idle":"2023-09-13T02:36:50.330129Z","shell.execute_reply.started":"2023-09-13T02:36:49.659032Z","shell.execute_reply":"2023-09-13T02:36:50.329215Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"import os\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)\n\nwiki_text_data = []\n\nfor file in tqdm(wikipedia_file_data.file.unique(), total=len(wikipedia_file_data.file.unique())):\n    _id = [str(i) for i in wikipedia_file_data[wikipedia_file_data['file']==file]['id'].tolist()]\n    _df = pd.read_parquet(f\"{WIKI_PATH}/{file}\", columns=['id', 'text'])\n\n    _df_temp = _df[_df['id'].isin(_id)].copy()\n    del _df\n    _ = gc.collect()\n    libc.malloc_trim(0)\n    wiki_text_data.append(_df_temp)\nwiki_text_data = pd.concat(wiki_text_data).drop_duplicates().reset_index(drop=True)\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:36:54.758477Z","iopub.execute_input":"2023-09-13T02:36:54.758981Z","iopub.status.idle":"2023-09-13T02:40:36.298530Z","shell.execute_reply.started":"2023-09-13T02:36:54.758942Z","shell.execute_reply":"2023-09-13T02:40:36.296723Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/28 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a6f4d4655324fae86668f884cf75e7c"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(wikipedia_file_data\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39munique(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(wikipedia_file_data\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;241m.\u001b[39munique())):\n\u001b[1;32m      8\u001b[0m     _id \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m wikipedia_file_data[wikipedia_file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mfile][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[0;32m----> 9\u001b[0m     _df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mWIKI_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     _df_temp \u001b[38;5;241m=\u001b[39m _df[_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(_id)]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _df\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:509\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    507\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parquet.py:227\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, dtype_backend, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    221\u001b[0m     path,\n\u001b[1;32m    222\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    223\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    224\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/parquet/core.py:2973\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2962\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2963\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2964\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2965\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2970\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   2971\u001b[0m         )\n\u001b[0;32m-> 2973\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2976\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2977\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2979\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2980\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyarrow/parquet/core.py:2601\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2593\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2594\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2595\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2596\u001b[0m         ]\n\u001b[1;32m   2597\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2598\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2599\u001b[0m         )\n\u001b[0;32m-> 2601\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"context_df = wikipedia_file_data.merge(wiki_text_data,on='id')\nprint(len(context_df))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:24:58.838132Z","iopub.execute_input":"2023-09-12T12:24:58.838500Z","iopub.status.idle":"2023-09-12T12:24:58.860058Z","shell.execute_reply.started":"2023-09-12T12:24:58.838464Z","shell.execute_reply":"2023-09-12T12:24:58.858819Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"600\n","output_type":"stream"}]},{"cell_type":"code","source":"context_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:24:58.861556Z","iopub.execute_input":"2023-09-12T12:24:58.862189Z","iopub.status.idle":"2023-09-12T12:24:58.880705Z","shell.execute_reply.started":"2023-09-12T12:24:58.862151Z","shell.execute_reply":"2023-09-12T12:24:58.879444Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id       file  \\\n0      1141        151  a.parquet   \n1  11963992        185  a.parquet   \n2      1200         63  a.parquet   \n3      1234        130  a.parquet   \n4      1317         89  a.parquet   \n\n                                                text  \n0  Augustin-Jean Fresnel (10 May 1788 – 14 July 1...  \n1  Atmospheric convection is the result of a parc...  \n2  Atomic physics is the field of physics that st...  \n3  Acoustic theory is a scientific field that rel...  \n4  In modern physics, antimatter is defined as ma...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>file</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1141</td>\n      <td>151</td>\n      <td>a.parquet</td>\n      <td>Augustin-Jean Fresnel (10 May 1788 – 14 July 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11963992</td>\n      <td>185</td>\n      <td>a.parquet</td>\n      <td>Atmospheric convection is the result of a parc...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200</td>\n      <td>63</td>\n      <td>a.parquet</td>\n      <td>Atomic physics is the field of physics that st...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1234</td>\n      <td>130</td>\n      <td>a.parquet</td>\n      <td>Acoustic theory is a scientific field that rel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1317</td>\n      <td>89</td>\n      <td>a.parquet</td>\n      <td>In modern physics, antimatter is defined as ma...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Spliting the wiki text in the context df in chunk size\n\nchunk_size = 1000\nchunk_overlap = 100\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\n\nsplit_text =[]\nfor i in range(len(context_df)):\n    split_text.append ( r_splitter.split_text(context_df.loc[i,'text']))\ncontext_df['split'] = split_text\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:24:58.883670Z","iopub.execute_input":"2023-09-12T12:24:58.884098Z","iopub.status.idle":"2023-09-12T12:25:01.547733Z","shell.execute_reply.started":"2023-09-12T12:24:58.884042Z","shell.execute_reply":"2023-09-12T12:25:01.546694Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"context_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T12:25:01.549139Z","iopub.execute_input":"2023-09-12T12:25:01.549597Z","iopub.status.idle":"2023-09-12T12:25:01.571241Z","shell.execute_reply.started":"2023-09-12T12:25:01.549561Z","shell.execute_reply":"2023-09-12T12:25:01.570158Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id       file  \\\n0      1141        151  a.parquet   \n1  11963992        185  a.parquet   \n2      1200         63  a.parquet   \n3      1234        130  a.parquet   \n4      1317         89  a.parquet   \n\n                                                text  \\\n0  Augustin-Jean Fresnel (10 May 1788 – 14 July 1...   \n1  Atmospheric convection is the result of a parc...   \n2  Atomic physics is the field of physics that st...   \n3  Acoustic theory is a scientific field that rel...   \n4  In modern physics, antimatter is defined as ma...   \n\n                                               split  \n0  [Augustin-Jean Fresnel (10 May 1788 – 14 July ...  \n1  [Atmospheric convection is the result of a par...  \n2  [Atomic physics is the field of physics that s...  \n3  [Acoustic theory is a scientific field that re...  \n4  [In modern physics, antimatter is defined as m...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>file</th>\n      <th>text</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1141</td>\n      <td>151</td>\n      <td>a.parquet</td>\n      <td>Augustin-Jean Fresnel (10 May 1788 – 14 July 1...</td>\n      <td>[Augustin-Jean Fresnel (10 May 1788 – 14 July ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11963992</td>\n      <td>185</td>\n      <td>a.parquet</td>\n      <td>Atmospheric convection is the result of a parc...</td>\n      <td>[Atmospheric convection is the result of a par...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1200</td>\n      <td>63</td>\n      <td>a.parquet</td>\n      <td>Atomic physics is the field of physics that st...</td>\n      <td>[Atomic physics is the field of physics that s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1234</td>\n      <td>130</td>\n      <td>a.parquet</td>\n      <td>Acoustic theory is a scientific field that rel...</td>\n      <td>[Acoustic theory is a scientific field that re...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1317</td>\n      <td>89</td>\n      <td>a.parquet</td>\n      <td>In modern physics, antimatter is defined as ma...</td>\n      <td>[In modern physics, antimatter is defined as m...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PREPARING THE PROMPT","metadata":{}},{"cell_type":"code","source":"text  = \"\"\"\nGive below is a question labelled as 'Q': , context labelled as 'T' :for additional ifnormation and 5 possible answers to the question labelled as 'A':,'B':,'C':,'D':,'E':. \n    'Answer the following question by outputting the letters A, B, C, D, and E '\\\n    'in order of the most likely to be correct to the to least likely to be correct\n'Q' : $q\n'T' : $t\n\n'A' : $a\n'B' : $b\n'C' : $c\n'D' : $d\n'E' : $e\n\n\n\"\"\"\n\ntemplate = Template(text)","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:40:36.299899Z","iopub.status.idle":"2023-09-13T02:40:36.300643Z","shell.execute_reply.started":"2023-09-13T02:40:36.300390Z","shell.execute_reply":"2023-09-13T02:40:36.300416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_dataframe(df, context_df):\n    \n    final_prompt = []\n    for i in range(len(df)):\n        q = df.loc[i,'prompt']\n        a = df.loc[i,'A']\n        b = df.loc[i,'B']\n        c = df.loc[i,'C']\n        d = df.loc[i,'D']\n        e = df.loc[i,'E']\n        \n        text = context_df[context_df['prompt_id'] == i].iloc[0]['split']\n\n        text_df = pd.DataFrame(text,columns=['text'])\n        vectors = model.encode(text_df['text'])\n        vector_dimension = vectors.shape[1]\n        index = faiss.IndexFlatL2(vector_dimension)\n        faiss.normalize_L2(vectors)\n        index.add(vectors)\n\n    \n        search_vector = model.encode(q)\n        _vector = np.array([search_vector])\n        faiss.normalize_L2(_vector)\n\n        k = 1\n        distances, ann = index.search(_vector, k=k)\n        chunk = text[ann[0,0]]\n\n        final_prompt.append(template.substitute(q=q,a = a,b=b,c=c,d=d,e=e,t=chunk))\n     #   break\n    \n    return final_prompt\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:40:36.302098Z","iopub.status.idle":"2023-09-13T02:40:36.302742Z","shell.execute_reply.started":"2023-09-13T02:40:36.302497Z","shell.execute_reply":"2023-09-13T02:40:36.302521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_dataframe(df, context_df):\n    \n #   final_prompt = []\n    for i in range(len(df)):\n        q = df.loc[i,'prompt']\n        a = df.loc[i,'A']\n        b = df.loc[i,'B']\n        c = df.loc[i,'C']\n        d = df.loc[i,'D']\n        e = df.loc[i,'E']\n        \n        text = context_df[context_df['prompt_id'] == i].iloc[0]['split']\n​\n        text_df = pd.DataFrame(text,columns=['text'])\n        vectors = model.encode(text_df['text'])\n        vector_dimension = vectors.shape[1]\n        index = faiss.IndexFlatL2(vector_dimension)\n        faiss.normalize_L2(vectors)\n        index.add(vectors)\n​\n    \n        search_vector = model.encode(q)\n        _vector = np.array([search_vector])\n        faiss.normalize_L2(_vector)\n​\n        k = 1\n        distances, ann = index.search(_vector, k=k)\n        chunk = text[ann[0,0]]\n        \n        df.loc[i,'context'] = chunk\n​\n  #      final_prompt.append(template.substitute(q=q,a = a,b=b,c=c,d=d,e=e,t=chunk))\n     #   break\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-09-13T02:40:36.430981Z","iopub.status.idle":"2023-09-13T02:40:36.432464Z","shell.execute_reply.started":"2023-09-13T02:40:36.432218Z","shell.execute_reply":"2023-09-13T02:40:36.432241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_df = format_dataframe(df_final,context_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"************PROMPTING THE MODEL TO GET RESPONSE","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:45:25.621288Z","iopub.execute_input":"2023-09-12T11:45:25.621711Z","iopub.status.idle":"2023-09-12T11:45:25.668353Z","shell.execute_reply.started":"2023-09-12T11:45:25.621682Z","shell.execute_reply":"2023-09-12T11:45:25.667389Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# The path of the model checkpoint we want to use\nmodel_dir = '/kaggle/input/huggingface-bert/bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(model_dir)\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir).cuda()\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:45:58.936855Z","iopub.execute_input":"2023-09-12T11:45:58.937420Z","iopub.status.idle":"2023-09-12T11:45:59.001565Z","shell.execute_reply.started":"2023-09-12T11:45:58.937386Z","shell.execute_reply":"2023-09-12T11:45:59.000372Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# We'll create a dictionary to convert option names (A, B, C, D, E) into indices and back again\noptions = 'ABCDE'\nindices = list(range(5))\n\noption_to_index = {option: index for option, index in zip(options, indices)}\nindex_to_option = {index: option for option, index in zip(options, indices)}\n\ndef preprocess(example):\n    # The AutoModelForMultipleChoice class expects a set of question/answer pairs\n    # so we'll copy our question 5 times before tokenizing\n    first_sentence = [example['prompt']] * 5\n    second_sentence = []\n    for option in options:\n        second_sentence.append(example[option])\n    # Our tokenizer will turn our text into token IDs BERT can understand\n    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:48:05.633488Z","iopub.execute_input":"2023-09-12T11:48:05.633880Z","iopub.status.idle":"2023-09-12T11:48:05.985511Z","shell.execute_reply.started":"2023-09-12T11:48:05.633850Z","shell.execute_reply":"2023-09-12T11:48:05.984587Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/200 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f51f72daa4d04344826ead1d46768b3b"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Following datacollator (adapted from https://huggingface.co/docs/transformers/tasks/multiple_choice)\n# will dynamically pad our questions at batch-time so we don't have to make every question the length\n# of our longest question.\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom typing import Optional, Union\nimport torch\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:46:52.609035Z","iopub.execute_input":"2023-09-12T11:46:52.609559Z","iopub.status.idle":"2023-09-12T11:46:52.622942Z","shell.execute_reply.started":"2023-09-12T11:46:52.609523Z","shell.execute_reply":"2023-09-12T11:46:52.621651Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Now we'll instatiate the model that we'll finetune on our public dataset, then use to\n# make prediction on the private dataset.\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nmodel = AutoModelForMultipleChoice.from_pretrained(model_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:46:53.776940Z","iopub.execute_input":"2023-09-12T11:46:53.777728Z","iopub.status.idle":"2023-09-12T11:46:59.153527Z","shell.execute_reply.started":"2023-09-12T11:46:53.777694Z","shell.execute_reply":"2023-09-12T11:46:59.152496Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Some weights of BertForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/huggingface-bert/bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# The arguments here are selected to run quickly; feel free to play with them.\nmodel_dir = 'finetuned_bert'\ntraining_args = TrainingArguments(\n    output_dir=model_dir,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    learning_rate=5e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    report_to='none'\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:47:02.558674Z","iopub.execute_input":"2023-09-12T11:47:02.559721Z","iopub.status.idle":"2023-09-12T11:47:02.568616Z","shell.execute_reply.started":"2023-09-12T11:47:02.559673Z","shell.execute_reply":"2023-09-12T11:47:02.567475Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Generally it's a bad idea to validate on your training set, but because our training set\n# for this problem is so small we're going to train on all our data.\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_train_ds,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:48:11.721946Z","iopub.execute_input":"2023-09-12T11:48:11.722674Z","iopub.status.idle":"2023-09-12T11:48:11.861942Z","shell.execute_reply.started":"2023-09-12T11:48:11.722640Z","shell.execute_reply":"2023-09-12T11:48:11.860877Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Training should take about a minute\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:48:12.921978Z","iopub.execute_input":"2023-09-12T11:48:12.922383Z","iopub.status.idle":"2023-09-12T11:49:11.857562Z","shell.execute_reply.started":"2023-09-12T11:48:12.922354Z","shell.execute_reply":"2023-09-12T11:49:11.856519Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [75/75 00:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.604195</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.584985</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.555638</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=75, training_loss=1.598838094075521, metrics={'train_runtime': 58.4739, 'train_samples_per_second': 10.261, 'train_steps_per_second': 1.283, 'total_flos': 155419127165040.0, 'train_loss': 1.598838094075521, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Now we can actually make predictions on our questions\npredictions = trainer.predict(tokenized_train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:49:29.022532Z","iopub.execute_input":"2023-09-12T11:49:29.022929Z","iopub.status.idle":"2023-09-12T11:49:32.876223Z","shell.execute_reply.started":"2023-09-12T11:49:29.022898Z","shell.execute_reply":"2023-09-12T11:49:32.875047Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# The following function gets the indices of the highest scoring answers for each row\n# and converts them back to our answer format (A, B, C, D, E)\nimport numpy as np\ndef predictions_to_map_output(predictions):\n    sorted_answer_indices = np.argsort(-predictions)\n    top_answer_indices = sorted_answer_indices[:,:3] # Get the first three answers in each row\n    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:49:36.753715Z","iopub.execute_input":"2023-09-12T11:49:36.754115Z","iopub.status.idle":"2023-09-12T11:49:36.764483Z","shell.execute_reply.started":"2023-09-12T11:49:36.754058Z","shell.execute_reply":"2023-09-12T11:49:36.762183Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Let's double check our output looks correct:\npredictions_to_map_output(predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:49:45.765588Z","iopub.execute_input":"2023-09-12T11:49:45.766180Z","iopub.status.idle":"2023-09-12T11:49:45.779926Z","shell.execute_reply.started":"2023-09-12T11:49:45.766140Z","shell.execute_reply":"2023-09-12T11:49:45.778910Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"array(['B D C', 'D C B', 'A C B', 'A C E', 'E D B', 'B A D', 'A C B',\n       'A D B', 'B D E', 'A E D', 'A E D', 'A D C', 'C B E', 'E A D',\n       'A B C', 'A B D', 'E C A', 'E A C', 'B A D', 'D A C', 'D B C',\n       'E B D', 'C D A', 'B C A', 'E D A', 'E B D', 'E C A', 'D C A',\n       'E B C', 'C E B', 'B D E', 'E C A', 'B E D', 'D E B', 'C B A',\n       'D A B', 'D A E', 'A C E', 'E A D', 'E A C', 'E A D', 'A C E',\n       'B A E', 'C D B', 'D C B', 'A B C', 'B C D', 'C B A', 'A B E',\n       'A B C', 'B D A', 'E D A', 'C A B', 'C A D', 'C E B', 'B E C',\n       'C A D', 'A C B', 'C A E', 'B D C', 'B D E', 'E B C', 'C A D',\n       'C B E', 'E C D', 'D B C', 'C E A', 'E D C', 'D E C', 'D E C',\n       'C D B', 'C D B', 'D E A', 'E B D', 'E C A', 'E C D', 'B A D',\n       'E A B', 'C E B', 'A E B', 'C D E', 'C A D', 'E D C', 'A E C',\n       'B C A', 'A B E', 'D A E', 'E A C', 'E A C', 'D B A', 'D A C',\n       'B C D', 'D A C', 'E D B', 'A B E', 'C B E', 'C D E', 'D B E',\n       'D C B', 'E C B', 'D B E', 'D C B', 'C E A', 'E B D', 'E D A',\n       'D E C', 'C A B', 'D E B', 'C A D', 'C D A', 'A C E', 'C D B',\n       'B C A', 'C E B', 'D A C', 'E B C', 'C B D', 'C D E', 'D C B',\n       'A B C', 'A C D', 'C B A', 'B E C', 'C E B', 'E B C', 'E D C',\n       'B C A', 'C B E', 'E B D', 'D E C', 'B D E', 'C E B', 'E A D',\n       'B E C', 'A C E', 'E A D', 'B C D', 'E B D', 'A B C', 'D A E',\n       'C A D', 'E B A', 'B A D', 'D A E', 'B E D', 'B E C', 'D C E',\n       'E B A', 'B A D', 'A B E', 'B A C', 'B A D', 'E D A', 'E B A',\n       'D B E', 'D B A', 'B D E', 'B A C', 'D A E', 'E A D', 'B A D',\n       'A B D', 'A C D', 'B D C', 'C B D', 'C D B', 'C B E', 'D C E',\n       'C E A', 'A D C', 'B C E', 'E B D', 'B E C', 'B E D', 'E B A',\n       'C E A', 'E A B', 'D C B', 'C D A', 'A E C', 'C B A', 'C E A',\n       'A C B', 'D E A', 'A D C', 'A D C', 'C E A', 'A D E', 'D A C',\n       'B C E', 'C D A', 'C D A', 'C E A', 'D E A', 'D E B', 'A D E',\n       'E D A', 'D B A', 'C B D', 'E B C'], dtype='<U5')"},"metadata":{}}]},{"cell_type":"code","source":"# Now we can load up our test set to use our model on!\n# The public test.csv isn't the real dataset (it's actually just a copy of train.csv without the answer column)\n# but it has the same format as the real test set, so using it is a good way to ensure our code will work when we submit.\ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:50:36.478315Z","iopub.execute_input":"2023-09-12T11:50:36.478696Z","iopub.status.idle":"2023-09-12T11:50:36.504655Z","shell.execute_reply.started":"2023-09-12T11:50:36.478666Z","shell.execute_reply":"2023-09-12T11:50:36.503623Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   id                                             prompt  \\\n0   0  Which of the following statements accurately d...   \n1   1  Which of the following is an accurate definiti...   \n2   2  Which of the following statements accurately d...   \n3   3  What is the significance of regularization in ...   \n4   4  Which of the following statements accurately d...   \n\n                                                   A  \\\n0  MOND is a theory that reduces the observed mis...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol was reconstructed as a fe...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   B  \\\n0  MOND is a theory that increases the discrepanc...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol is a representation of th...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   C  \\\n0  MOND is a theory that explains the missing bar...   \n1  Dynamic scaling refers to the evolution of sel...   \n2  The triskeles symbol is a representation of a ...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   D  \\\n0  MOND is a theory that reduces the discrepancy ...   \n1  Dynamic scaling refers to the non-evolution of...   \n2  The triskeles symbol represents three interloc...   \n3  Regularizing the mass-energy of an electron wi...   \n4  The angular spacing of features in the diffrac...   \n\n                                                   E  \n0  MOND is a theory that eliminates the observed ...  \n1  Dynamic scaling refers to the evolution of sel...  \n2  The triskeles symbol is a representation of th...  \n3  Regularizing the mass-energy of an electron wi...  \n4  The angular spacing of features in the diffrac...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nllm = '/kaggle/input/flan-t5/pytorch/small/2'\n\nmodel_llm = T5ForConditionalGeneration.from_pretrained(llm,local_files_only = True).to(device)\ntokenizer_llm = T5Tokenizer.from_pretrained(llm)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:02:09.290890Z","iopub.execute_input":"2023-09-12T11:02:09.291281Z","iopub.status.idle":"2023-09-12T11:02:14.967934Z","shell.execute_reply.started":"2023-09-12T11:02:09.291251Z","shell.execute_reply":"2023-09-12T11:02:14.966854Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}]},{"cell_type":"code","source":"# checking for one response\n\ninputs = tokenizer_llm(model_prompt[0], return_tensors=\"pt\").to(device)\noutputs = model_llm.generate(**inputs)\nanswer = tokenizer_llm.batch_decode(outputs, skip_special_tokens=True)\n\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:02:17.103320Z","iopub.execute_input":"2023-09-12T11:02:17.104018Z","iopub.status.idle":"2023-09-12T11:02:18.586219Z","shell.execute_reply.started":"2023-09-12T11:02:17.103982Z","shell.execute_reply":"2023-09-12T11:02:18.585141Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"['A']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SUBMISSION **","metadata":{}},{"cell_type":"code","source":"def post_process(predictions):\n    valid = set(['A', 'B', 'C', 'D', 'E'])\n    # If there are no valid choices, return something and hope for partial credit\n    if set(predictions).isdisjoint(valid):\n        final_pred = 'A B C D E'\n    else:\n        final_pred = []\n        for prediction in predictions:\n            if prediction in valid:\n                final_pred += prediction\n        # add remaining letters\n        to_add = valid - set(final_pred)\n        final_pred.extend(list(to_add))\n        # put in space-delimited format\n        final_pred = ' '.join(final_pred)\n        \n    return final_pred\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/sample_submission.csv', index_col='id')\n\ni = 0\nfor text in model_prompt:\n    inputs = tokenizer_llm(text, return_tensors=\"pt\").to(device)\n    outputs = model_llm.generate(**inputs)\n    answer = tokenizer_llm.batch_decode(outputs, skip_special_tokens=True)\n    submission.loc[i,'prediction'] = post_process(answer)\n    i = i+1\n\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:03:57.148588Z","iopub.execute_input":"2023-09-12T11:03:57.148952Z","iopub.status.idle":"2023-09-12T11:04:06.829868Z","shell.execute_reply.started":"2023-09-12T11:03:57.148925Z","shell.execute_reply":"2023-09-12T11:04:06.828914Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-09-12T11:03:54.215709Z","iopub.execute_input":"2023-09-12T11:03:54.216132Z","iopub.status.idle":"2023-09-12T11:03:54.223699Z","shell.execute_reply.started":"2023-09-12T11:03:54.216091Z","shell.execute_reply":"2023-09-12T11:03:54.222405Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}